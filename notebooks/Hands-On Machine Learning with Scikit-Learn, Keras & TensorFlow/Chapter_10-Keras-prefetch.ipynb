{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow\n",
    "## Chapter 10 - Introduction to Artificial Neural Networks with Keras\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import concurrent.futures\n",
    "import hashlib\n",
    "import io\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.keras.layers\n",
    "\n",
    "from tensorflow_2 import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir(desc: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    Generate path to new run log directory.\n",
    "    \n",
    "    :param desc: run description\n",
    "    :return: log file path with timestamp and optional description\n",
    "    \"\"\"\n",
    "    return LOG_DIR / time.strftime(f'{desc}-%Y_%m_%d_%H_%M_%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "DATA_DIR = utils.package_dir() / 'data'/ 'ch10'\n",
    "LOG_DIR = DATA_DIR / 'logs'\n",
    "TRAIN_DIR = DATA_DIR / 'train'\n",
    "VAL_DIR = DATA_DIR / 'val'\n",
    "TEST_DIR = DATA_DIR / 'test'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "DROPOUT_P = 0.45\n",
    "EPOCHS = 10000\n",
    "VAL_FREQ = 512 // BATCH_SIZE\n",
    "\n",
    "best_model = 'best_model.h5'\n",
    "model_ckpt = 'model_ckpt.h5'\n",
    "\n",
    "RUN_DIR = get_run_logdir(f'baseline_cnn-batch_{BATCH_SIZE}')\n",
    "PLOTS_DIR = RUN_DIR / 'plots'\n",
    "BEST_MODEL = RUN_DIR / best_model\n",
    "MODEL_CKPT = RUN_DIR / model_ckpt\n",
    "\n",
    "PREVIOUS_RUN = LOG_DIR / 'baseline_cnn-batch_32-2020_11_26_17_02_23'\n",
    "PREVIOUS_BEST_MODEL = PREVIOUS_RUN / best_model\n",
    "PREVIOUS_MODEL_CKPT = PREVIOUS_RUN / model_ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Data\n",
    "[Fashion MNIST Dataset](https://keras.io/api/datasets/fashion_mnist/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = (\n",
    "    tf.keras.datasets.fashion_mnist.load_data()\n",
    "    )\n",
    "print(f'Train Shape: {x_train_full.shape}')\n",
    "print(f'Train Data Type: {x_train_full.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Validation Stratified Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train_full,\n",
    "    y_train_full,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=y_train_full\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\n",
    "    't-shirt_top',\n",
    "    'trouser',\n",
    "    'pullover',\n",
    "    'dress',\n",
    "    'coat',\n",
    "    'sandal',\n",
    "    'shirt',\n",
    "    'sneaker',\n",
    "    'bag',\n",
    "    'ankle_boot',\n",
    "    )\n",
    "CLASSES_IDX = {n: v for n, v in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=y_train, name='Train'))\n",
    "fig.add_trace(go.Histogram(x=y_val, name='Validation'))\n",
    "fig.add_trace(go.Histogram(x=y_test, name='Test'))\n",
    "\n",
    "fig.update_traces(opacity=0.7)\n",
    "fig.update_layout(\n",
    "    title_text='Dataset Distributions',\n",
    "    xaxis=dict(\n",
    "        title='Class',\n",
    "        tickvals=tuple(CLASSES_IDX.keys()),\n",
    "        ticktext=tuple(CLASSES_IDX.values()),\n",
    "    ),\n",
    "    yaxis_title_text='Count',\n",
    "    bargroupgap=0.1,\n",
    "    barmode='group'\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data to Files\n",
    "\n",
    "This will more mimic an actual use case where the images are too large to be held in memory.\n",
    "\n",
    "To use the following structure:\n",
    "```\n",
    "data_dir/\n",
    "  train_dir/\n",
    "    class_0/\n",
    "      #.jpg\n",
    "      #.jpg\n",
    "    ...\n",
    "    class_n/\n",
    "      #.jpg\n",
    "      #.jpg\n",
    "  val_dir/\n",
    "    class_0/\n",
    "      #.jpg\n",
    "      #.jpg\n",
    "    ...\n",
    "    class_n/\n",
    "      #.jpg\n",
    "      #.jpg\n",
    "  test_dir/\n",
    "    class_0/\n",
    "      #.jpg\n",
    "      #.jpg\n",
    "    ...\n",
    "    class_n/\n",
    "      #.jpg\n",
    "      #.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = (\n",
    "    (x_train, y_train, TRAIN_DIR),\n",
    "    (x_val, y_val, VAL_DIR),\n",
    "    (x_test, y_test, TEST_DIR),\n",
    "    )\n",
    "\n",
    "for x, y, directory in datasets:\n",
    "    print(f'Saving Dataset Images: {directory}')\n",
    "    # create directories\n",
    "    for label in np.unique(y):\n",
    "        (directory / CLASSES_IDX[label]).mkdir(parents=True,\n",
    "                                               exist_ok=True)\n",
    "    # save images\n",
    "    with concurrent.futures.ProcessPoolExecutor() as pool:\n",
    "        futures = []\n",
    "        for im, label in zip(x, y):\n",
    "            path = (directory / CLASSES_IDX[label]\n",
    "                    / f'{hashlib.sha256(im).hexdigest()}.png')\n",
    "            if not path.is_file():\n",
    "                futures.append(pool.submit(cv2.imwrite, str(path), im))\n",
    "        for f in concurrent.futures.as_completed(futures):\n",
    "            f.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Image Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in TRAIN_DIR.glob('**/*'):\n",
    "    if x.suffix == '.png':\n",
    "        im = cv2.imread(str(x))\n",
    "        IM_HEIGHT, IM_WIDTH, IM_CHANNELS = im.shape\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "#     image_size=(IM_HEIGHT, IM_WIDTH),  # TODO: add Resizing layer to model\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    )\n",
    "train_classes = train_data.class_names\n",
    "\n",
    "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    VAL_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "#     image_size=(IM_HEIGHT, IM_WIDTH),\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    )\n",
    "val_classes = val_data.class_names\n",
    "\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TEST_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='grayscale',\n",
    "    batch_size=BATCH_SIZE,\n",
    "#     image_size=(IM_HEIGHT, IM_WIDTH),\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    )\n",
    "test_classes = test_data.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Prefetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_data = val_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_data = test_data.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_data.take(1)))\n",
    "for n in range(10):\n",
    "    ax = plt.subplot(2, 5, n + 1)\n",
    "    ax.imshow(x[n], cmap='gray')\n",
    "    ax.set_title(train_classes[y[n]])\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = 1 / np.iinfo(x_train.dtype).max\n",
    "\n",
    "im_gen_train = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    rescale=scale_factor,\n",
    "    )\n",
    "\n",
    "im_gen_val = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=scale_factor,\n",
    "    )\n",
    "\n",
    "train_data_gen = im_gen_train.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='sparse',\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    target_size=(28, 28),\n",
    "    )\n",
    "train_classes = {v: k for k, v in train_data_gen.class_indices.items()}\n",
    "\n",
    "val_data_gen = im_gen_val.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='sparse',\n",
    "    seed=42,\n",
    "    target_size=(28, 28),\n",
    "    )\n",
    "val_classes = {v: k for k, v in val_data_gen.class_indices.items()}\n",
    "\n",
    "test_data_gen = im_gen_val.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='sparse',\n",
    "    seed=42,\n",
    "    target_size=(28, 28),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(train_data_gen)\n",
    "for n in range(10):\n",
    "    ax = plt.subplot(2, 5, n + 1)\n",
    "    ax.imshow(x[n], cmap='gray')\n",
    "    ax.set_title(train_classes[y[n]])\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     InputLayer(input_shape=(28, 28, 1)),\n",
    "#     Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "#     Dropout(DROPOUT_P),\n",
    "#     Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "#     Dropout(DROPOUT_P),\n",
    "#     Flatten(),\n",
    "#     Dense(10, activation='softmax'),\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Model\n",
    "Allows multiple inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_0 = Input(shape=(28, 28, 1), name='input_0')\n",
    "hidden_0 = Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu')(input_0)\n",
    "hidden_1 = Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu')(hidden_0)\n",
    "flatten_1 = Flatten()(hidden_1)\n",
    "output_0 = Dense(10, activation='softmax', name='output_0')(flatten_1)\n",
    "model = tf.keras.Model(inputs=[input_0], outputs=[output_0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model\n",
    "\n",
    "<br>\n",
    "<font color='red'>\n",
    "    WARNING:<br>\n",
    "    With the current version of Keras if a saved model is loaded and not compiled inference scores are random.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(m):\n",
    "    return m.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREVIOUS_BEST_MODEL.exists():\n",
    "    model = tf.keras.models.load_model(PREVIOUS_BEST_MODEL)\n",
    "elif PREVIOUS_MODEL_CKPT.exists():\n",
    "    model = tf.keras.models.load_model(PREVIOUS_MODEL_CKPT)\n",
    "\n",
    "compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard\n",
    "\n",
    "<br>\n",
    "<font color=red>\n",
    "    Start TensorBoard before fitting the model.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs=None):\n",
    "    \"\"\"Save confussion matrix to be displayed in TensorBoard.\"\"\"\n",
    "    if epoch > 0 and epoch % VAL_FREQ == 0:\n",
    "        predict = np.argmax(model.predict(val_data_gen), axis=1)\n",
    "        cm = tf.math.confusion_matrix(val_data_gen.classes, predict)\n",
    "        fig = confusion_matrix_fig(cm, CLASSES_IDX)\n",
    "        cm_image = plotly_static_image(fig)\n",
    "\n",
    "        file_writer = tf.summary.create_file_writer(str(PLOTS_DIR / 'cm'))\n",
    "        with file_writer.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, epoch)\n",
    "\n",
    "        \n",
    "def confusion_matrix_fig(cm: tf.Tensor, classes: Dict[int, str]):\n",
    "    \"\"\"\n",
    "    Generate confusion matrix figure.\n",
    "    \n",
    "    :param cm: confusion matrix (r, c = actual, predicted)\n",
    "    :param classes: dictionary with class index as key and class name as value\n",
    "    :return: confusion matrix figure\n",
    "    \"\"\"\n",
    "    normalized = cm / tf.math.reduce_sum(cm, axis=1, keepdims=True)\n",
    "    normalized = tf.linalg.set_diag(normalized, np.zeros((normalized.shape[0])))\n",
    "    fig = px.imshow(\n",
    "        normalized,\n",
    "        color_continuous_scale='gray',\n",
    "        labels=dict(x='Predicted', y='Actual', color='Error Rate'),\n",
    "        title='Confusion Matrix Error Rates',\n",
    "        x=list(range(10)),\n",
    "        y=list(range(10)),\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text='Confusion Matrix',\n",
    "        xaxis=dict(\n",
    "            title='Predicted Class',\n",
    "            tickvals=tuple(classes.keys()),\n",
    "            ticktext=tuple(classes.values()),\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Actual Class',\n",
    "            tickvals=tuple(classes.keys()),\n",
    "            ticktext=tuple(classes.values()),\n",
    "        ),\n",
    "        )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def plotly_static_image(fig):\n",
    "    \"\"\"\n",
    "    Convert Plotly figure to a static image.\n",
    "    \n",
    "    :param fig: Plotyly figure\n",
    "    \"\"\"\n",
    "    im_bytes = fig.to_image(format='png')\n",
    "    tf_im = tf.image.decode_png(im_bytes, 3)\n",
    "    return tf.expand_dims(tf_im, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Sample Images for TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prediction_examples(epoch, logs=None):\n",
    "    \"\"\"Save prediction examples to be displayed in TensorBoard.\"\"\"\n",
    "    if epoch > 0 and epoch % VAL_FREQ == 0:\n",
    "        fig = prediction_examples_fig()\n",
    "        im = pyplot_static_image(fig)\n",
    "\n",
    "        file_writer = (\n",
    "            tf.summary.create_file_writer(str(PLOTS_DIR / 'predictions'))\n",
    "            )\n",
    "        with file_writer.as_default():\n",
    "            tf.summary.image(\"Predictions\", im, epoch)\n",
    "    \n",
    "\n",
    "def prediction_examples_fig(n_examples: int = BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Image and prediction percentages.\n",
    "    \n",
    "    :param n_examples: number of images to evaluate\n",
    "    \"\"\"\n",
    "    n_examples = n_examples if n_examples <= BATCH_SIZE else BATCH_SIZE\n",
    "    cols = 2\n",
    "    rows = int(np.ceil(n_examples / cols))\n",
    "    fig = plt.figure(figsize=(8 * cols, 4 * rows))\n",
    "    outer = gridspec.GridSpec(rows, cols, wspace=0.4, hspace=0.4)\n",
    "    \n",
    "    x, y = next(val_data_gen)\n",
    "    predict = model.predict((x, y))\n",
    "    y_hat = np.argmax(predict, axis=1)\n",
    "\n",
    "    for n in range(n_examples):\n",
    "        inner = gridspec.GridSpecFromSubplotSpec(\n",
    "            1, 2, subplot_spec=outer[n], wspace=0.1, hspace=0.1)\n",
    "        \n",
    "        # Image\n",
    "        ax = plt.Subplot(fig, inner[0])\n",
    "        ax.imshow(x[n], cmap='gray')\n",
    "        title = f'{val_classes[y_hat[n]]} {predict[n].max():.0%}'\n",
    "        if y_hat[n] == y[n]:\n",
    "            color = 'blue'\n",
    "        else:\n",
    "            color = 'red'\n",
    "            title = title + f'\\nActual: {val_classes[y[n]]}'\n",
    "        ax.set_title(title, fontsize=20, color=color)\n",
    "        ax.axis('off')\n",
    "        fig.add_subplot(ax)\n",
    "        \n",
    "        # Predictions\n",
    "        ax = plt.Subplot(fig, inner[1])        \n",
    "        bar = ax.bar(range(10), predict[n], color='grey')\n",
    "        bar[y_hat[n]].set_color('red')\n",
    "        bar[int(y[n])].set_color('blue')\n",
    "        ax.set_title(f'Example: {n}', fontsize=20, color=color)\n",
    "        ax.axis('off')\n",
    "        ax.set_ylim([0, 1])\n",
    "        fig.add_subplot(ax)\n",
    "            \n",
    "    return fig\n",
    "\n",
    "\n",
    "def pyplot_static_image(fig):\n",
    "    \"\"\"\n",
    "    Convert Matplotlib pyplot figure to a static image.\n",
    "    \n",
    "    :param fig: pyplot figure\n",
    "    \"\"\"\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png')\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    tf_im = tf.image.decode_png(buf.getvalue(), 3)\n",
    "    return tf.expand_dims(tf_im, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir $LOG_DIR --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    MODEL_CKPT,\n",
    "    save_freq=32,\n",
    "    )\n",
    "\n",
    "confusion_matrix_cb = tf.keras.callbacks.LambdaCallback(\n",
    "    on_epoch_end=log_confusion_matrix\n",
    "    )\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=16,\n",
    "    restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "prediction_examples_cb = tf.keras.callbacks.LambdaCallback(\n",
    "    on_epoch_end=log_prediction_examples\n",
    "    )\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(RUN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "`fit()` method\n",
    "- if dataset is skewed add `class_weight` argument\n",
    "- use `sample_weight` argument to if the reliability of the label is different per instance (experts evaluated some labels, while others were labeled by an angorithm)\n",
    "\n",
    "NOTE:\n",
    "The time when Accuracy is calculated is not the same for the train dataset as the validation dataset.\n",
    "- Validation: calculated ***end*** of each epoch\n",
    "- Training: running mean ***durring*** each epoch\n",
    "\n",
    "To compensate the training metrics should be shifted by $\\frac{1}{2}$ an epoch to the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=4,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_freq=VAL_FREQ,\n",
    "    callbacks=[\n",
    "        checkpoint_cb,\n",
    "        confusion_matrix_cb,\n",
    "        early_stopping_cb,\n",
    "        prediction_examples_cb,\n",
    "        tensorboard_cb,\n",
    "    ],\n",
    "    steps_per_epoch=2 * len(train_data_gen) // BATCH_SIZE,\n",
    "    workers=2,\n",
    "    use_multiprocessing=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Test Set\n",
    "- Estimate generalization error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_data_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(BEST_MODEL, save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file=RUN_DIR / 'model_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(BEST_MODEL)\n",
    "compile_model(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.evaluate(test_data_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
