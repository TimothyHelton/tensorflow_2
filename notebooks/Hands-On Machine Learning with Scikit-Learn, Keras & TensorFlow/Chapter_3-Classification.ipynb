{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow\n",
    "\n",
    "## Chapter 2: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_recall_curve, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "\n",
    "from tensorflow_2.exceptions import InputError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('../../data/ch3_classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, data_home=DATA_DIR.parent)\n",
    "print(mnist['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist['target'] = mnist['target'].astype(np.uint8)\n",
    "x_train, y_train = [mnist[k][:60000] for k in ('data', 'target')]\n",
    "x_test, y_test = [mnist[k][60000:] for k in ('data', 'target')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example(dset: str='train', idx: int=0, score: Optional[bool]=None):\n",
    "    \"\"\"\n",
    "    Plot example from dataset.\n",
    "    \n",
    "    :param dset: choose either `train` or `test`\n",
    "    :param idx: index of example\n",
    "    :param score: model predicted score\n",
    "    \"\"\"\n",
    "    if dset not in ('train', 'test'):\n",
    "        raise InputError(\n",
    "            f'dset={dset}',\n",
    "            f'Valid inputs for dset are \"train\" or \"test\"')\n",
    "    x = x_train if dset == 'train' else x_test\n",
    "    y = y_train if dset == 'train' else y_test\n",
    "    score = '' if score is None else f'   Predict: {score}'\n",
    "    plt.imshow(x[idx].reshape(28, 28), cmap='binary')\n",
    "    plt.title(f'Label: {y[idx]}{score}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plot_example('train', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train Binary Classifier\n",
    "\n",
    "Stochastic Gradient Descent (SGD) classifier\n",
    "- capable of handling very large datasets efficiently\n",
    "- evaluates training instances independently\n",
    "    - suited for online learning\n",
    "- relies on randomness during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_value = 4\n",
    "y_train_binary = y_train == binary_value\n",
    "y_test_binary = y_test == binary_value\n",
    "\n",
    "sgd_classifier = SGDClassifier(random_state=42)\n",
    "sgd_classifier.fit(x_train, y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(10):\n",
    "    score = sgd_classifier.predict([x_train[n]])[0]\n",
    "    plot_example(dset='train', idx=n, score=score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cross-Validation of Binary Classifier\n",
    "\n",
    "Algorithm\n",
    "1. Randomly split the training set in k distinct subsets called ***folds***.\n",
    "1. Train the model on k-1 folds.\n",
    "1. Evaluate the model on the one fold that was not included in training.\n",
    "1. Repeat until all folds have been used as an evaluation set.\n",
    "1. Average the results of all the trained folds.\n",
    "\n",
    "### Example implementation of Cross-Validation\n",
    "```python\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "score = []\n",
    "for train_idx, test_idx in skfolds.split(x_train, y_train):\n",
    "    clone_model = clone(model)\n",
    "    x_train_folds = x_train[train_idx]\n",
    "    y_train_folds = y_train[train_idx]\n",
    "    x_test_fold = x_train[test_idx]\n",
    "    y_test_fold = y_train[test_idx]\n",
    "    clone_model.fit(x_train_folds, y_train_folds)\n",
    "    predict = clone_model.predict(x_test_fold)\n",
    "    n_correct = sum(predict == y_test_fold)\n",
    "    score.append(n_correct / len(pedict)) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Cross-Validataion Accuracy of Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(sgd_classifier, x_train, y_train_binary, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the classifier said a two never appeared in this dataset the model would have an accuracy of 90%.\n",
    "\n",
    "<font color='red'>\n",
    "    Accuracy is generally not the preferred performance measure for classifiers, especially when dealing with *skewed* datasets.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix of Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = cross_val_predict(sgd_classifier, x_train, y_train_binary, cv=3)\n",
    "c_matrix = confusion_matrix(y_train_binary, y_train_pred)\n",
    "pd.DataFrame(c_matrix,\n",
    "             columns=['Predicted False', 'Predicted True'],\n",
    "             index=['Actual False', 'Actual True'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "    <b>\n",
    "        Increasing precision reduces recall, and vice versa (Precision/Recal trade-off)\n",
    "    </b>\n",
    "</font>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<font color='green'>\n",
    "    For the binary case: tn, fp, fn, tp = confusion_matrix().ravel()\n",
    "</font>\n",
    "\n",
    "#### Precision\n",
    "$$precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "#### Recall\n",
    "$$recall = \\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = c_matrix.ravel()\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "    Use Scikit-Learn functions for Precision and Recall\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall = [f(y_train_binary, y_train_pred)\n",
    "                     for f in (precision_score, recall_score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score\n",
    "\n",
    "- Combination of precision and recall into a single metric.\n",
    "- The harmonic mean of precision and recall.\n",
    "- Metric gives much more weight to low values.\n",
    "- A high F1 score requires *both* precision and recall to be high.\n",
    "\n",
    "$$F_1 = \\frac{2}{\\frac{1}{precision} + \\frac{1}{recall}}$$\n",
    "\n",
    "$$F_1 = 2 \\left( \\frac{precision \\cdot recall}{precision + recall} \\right)$$\n",
    "\n",
    "$$F_1 = \\frac{TP}{TP + \\frac{FN + FP}{2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_train_binary, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision vs. Recall\n",
    "\n",
    "- Increasing the threshold decreases recall and will generally impove precision (sometimes precision will decrease)\n",
    "- Lowering the threshold increases recall and reduces precision\n",
    "\n",
    "<font color='red'>\n",
    "    Scikit-Learn uses a default threshold of zero.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_function_scores = cross_val_predict(\n",
    "    sgd_classifier, x_train, y_train_binary, cv=3, method='decision_function'\n",
    ")\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(\n",
    "    y_train_binary, decision_function_scores\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    np.c_[precisions[:-1], recalls[:-1]],\n",
    "    index=thresholds,\n",
    "    columns=['Precision', 'Recall'],\n",
    ")\n",
    "df.index.name='Threshold'\n",
    "\n",
    "fig = px.line(df, title='Precision & Recall vs Threshold')\n",
    "fig.show()\n",
    "\n",
    "fig = px.line(df, x='Recall', y='Precision', title='Precision vs Threshold')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Threshold to Acheive 90% Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_90_precision = thresholds[np.argmax(precisions >= 0.9)]\n",
    "y_train_pred_90 = decision_function_scores >= threshold_90_precision\n",
    "\n",
    "precision, recall = [f(y_train_binary, y_train_pred_90)\n",
    "                     for f in (precision_score, recall_score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
