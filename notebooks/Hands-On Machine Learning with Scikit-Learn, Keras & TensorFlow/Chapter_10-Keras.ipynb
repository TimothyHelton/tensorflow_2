{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow\n",
    "## Chapter 10 - Introduction to Artificial Neural Networks with Keras\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import concurrent.futures\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, InputLayer\n",
    "\n",
    "from tensorflow_2 import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = utils.package_dir() / 'data'/ 'ch10'\n",
    "LOG_DIR = DATA_DIR / 'logs'\n",
    "TRAIN_DIR = DATA_DIR / 'train'\n",
    "VAL_DIR = DATA_DIR / 'val'\n",
    "TEST_DIR = DATA_DIR / 'test'\n",
    "\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir():\n",
    "    \"\"\"Generate path to new run log directory.\"\"\"\n",
    "    return LOG_DIR / time.strftime('run_%Y-%m-%d_%H-%M-%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = (\n",
    "    tf.keras.datasets.fashion_mnist.load_data()\n",
    "    )\n",
    "print(f'Train Shape: {x_train_full.shape}')\n",
    "print(f'Train Data Type: {x_train_full.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\n",
    "    't-shirt_top',\n",
    "    'trouser',\n",
    "    'pullover',\n",
    "    'dress',\n",
    "    'coat',\n",
    "    'sandal',\n",
    "    'shirt',\n",
    "    'sneaker',\n",
    "    'bag',\n",
    "    'ankle_boot',\n",
    "    )\n",
    "classes_idx = {n: v for n, v in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Validation Stratified Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train_full,\n",
    "    y_train_full,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=y_train_full\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=y_train, name='Train'))\n",
    "fig.add_trace(go.Histogram(x=y_val, name='Validation'))\n",
    "fig.add_trace(go.Histogram(x=y_test, name='Test'))\n",
    "\n",
    "fig.update_traces(opacity=0.7)\n",
    "fig.update_layout(\n",
    "    title_text='Dataset Distributions',\n",
    "    xaxis=dict(\n",
    "        title='Class',\n",
    "        tickvals=tuple(classes_idx.keys()),\n",
    "        ticktext=tuple(classes_idx.values()),\n",
    "    ),\n",
    "    yaxis_title_text='Count',\n",
    "    bargroupgap=0.1,\n",
    "    barmode='group'\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data to Files\n",
    "\n",
    "This will more mimic an actual use case where the images are too large to be held in memory.\n",
    "\n",
    "To use the following structure:\n",
    "```\n",
    "data_dir/\n",
    "  train_dir/\n",
    "    class_0/\n",
    "      #.jpg\n",
    "      #.jpg\n",
    "    ...\n",
    "    class_n/\n",
    "      #.jpg\n",
    "      #.jpg\n",
    "  val_dir/\n",
    "    class_0/\n",
    "      #.jpg\n",
    "      #.jpg\n",
    "    ...\n",
    "    class_n/\n",
    "      #.jpg\n",
    "      #.jpg\n",
    "  test_dir/\n",
    "    class_0/\n",
    "      #.jpg\n",
    "      #.jpg\n",
    "    ...\n",
    "    class_n/\n",
    "      #.jpg\n",
    "      #.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = (\n",
    "    (x_train, y_train, TRAIN_DIR),\n",
    "    (x_val, y_val, VAL_DIR),\n",
    "    (x_test, y_test, TEST_DIR),\n",
    "    )\n",
    "\n",
    "for x, y, directory in datasets:\n",
    "    print(f'Saving Dataset Images: {directory}')\n",
    "    # create directories\n",
    "    for label in np.unique(y):\n",
    "        (directory / classes_idx[label]).mkdir(parents=True,\n",
    "                                               exist_ok=True)\n",
    "    # save images\n",
    "    with concurrent.futures.ProcessPoolExecutor() as pool:\n",
    "        futures = []\n",
    "        for im, label in zip(x, y):\n",
    "            path = (directory / classes_idx[label]\n",
    "                    / f'{hashlib.sha256(im).hexdigest()}.png')\n",
    "            if not path.is_file():\n",
    "                futures.append(pool.submit(cv2.imwrite, str(path), im))\n",
    "        for f in concurrent.futures.as_completed(futures):\n",
    "            f.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = 1 / np.iinfo(x_train.dtype).max\n",
    "\n",
    "im_gen_train = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    rescale=scale_factor,\n",
    "    )\n",
    "\n",
    "im_gen_val = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=scale_factor,\n",
    "    )\n",
    "\n",
    "train_data_gen = im_gen_train.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='sparse',\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    target_size=(28, 28),\n",
    "    )\n",
    "\n",
    "val_data_gen = im_gen_train.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='sparse',\n",
    "    seed=42,\n",
    "    target_size=(28, 28),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(train_data_gen)\n",
    "data_gen_classes = {v: k for k, v in train_data_gen.class_indices.items()}\n",
    "for n in range(10):\n",
    "    ax = plt.subplot(2, 5, n + 1)\n",
    "    ax.imshow(x[n], cmap='gray')\n",
    "    ax.set_title(data_gen_classes[y[n]])\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    InputLayer(input_shape=(28, 28, 1)),\n",
    "    Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(get_run_logdir())\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    epochs=15,\n",
    "    steps_per_epoch=len(train_data_gen) // BATCH_SIZE,\n",
    "    validation_data=val_data_gen,\n",
    "    callbacks=[tensorboard_cb],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir LOG_DIR --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
