{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow\n",
    "\n",
    "## Chapter 2: Housing Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import tarfile\n",
    "from typing import Optional, Tuple\n",
    "import urllib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import iplot\n",
    "from scipy import stats\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, TweedieRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout)\n",
    "logger = logging.getLogger('housing')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "# Fonts\n",
    "AXIS_FONT = {\n",
    "    'color': 'gray',\n",
    "    'family': 'Arial, sans-serif',\n",
    "    'size': 18,\n",
    "}\n",
    "\n",
    "TICK_FONT = {\n",
    "    'color': 'black',\n",
    "    'family': 'Old Standard TT, serif',\n",
    "    'size': 14,\n",
    "}\n",
    "\n",
    "TITLE_FONT = {\n",
    "    'color': 'black',\n",
    "    'family': 'Arial, sans-serif',\n",
    "    'size': 24,\n",
    "}\n",
    "\n",
    "PARAMS = {\n",
    "    'axes.labelsize': 14,\n",
    "    'axes.titlesize': 20,\n",
    "    'figure.titlesize': 24,\n",
    "    'legend.fontsize': 12,\n",
    "}\n",
    "plt.rcParams.update(PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = 'median_house_value'\n",
    "\n",
    "N_TRAIN = {}\n",
    "\n",
    "FILE = 'housing.tgz'\n",
    "DOWNLOAD_ROOT = 'https://raw.githubusercontent.com/ageron/handson-ml2/master'\n",
    "HOUSING_URL = f'{DOWNLOAD_ROOT}/datasets/housing/{FILE}'\n",
    "DATA_DIR = Path('../../data/')\n",
    "DATA_FILE = DATA_DIR / FILE\n",
    "\n",
    "TRAIN_SET_DATA = DATA_DIR / 'housing_train.pickle'\n",
    "TEST_SET_DATA = DATA_DIR / 'housing_test.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def download_housing():\n",
    "    \"\"\"Download housing data.\"\"\"\n",
    "    DATA_DIR.mkdir(exist_ok=True)\n",
    "    if not DATA_FILE.is_file():\n",
    "        urllib.request.urlretrieve(HOUSING_URL, DATA_FILE)\n",
    "        logger.debug('Downloaded data from URL: %s' % HOUSING_URL)\n",
    "        with tarfile.open(DATA_FILE, 'r') as f:\n",
    "            f.extractall(DATA_DIR)\n",
    "        logger.debug('Extracted %s to %s' % (DATA_FILE.name, DATA_DIR.resolve()))\n",
    "    logger.debug('Using cached data file: %s' % DATA_FILE.resolve())\n",
    "    \n",
    "\n",
    "download_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(DATA_FILE.with_suffix('.csv')).sort_index(axis=1)\n",
    "d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['ocean_proximity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.hist(bins=50, figsize=(20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Split Dataset\n",
    "\n",
    "**Assumptions:**\n",
    "\n",
    "- The median income is a strong predictor of median house price.\n",
    "\n",
    "\n",
    "**Processing Method**\n",
    "\n",
    "- Batch Training\n",
    "    - Any retraining will involve all the data so tracking the split is not required.\n",
    "- Online Training\n",
    "    - As long as each mini-batch was prepared with the same stratified split and no instances were repeated the data could be injested for training.\n",
    "    - The training set would have to grow with each new load of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(stratify: Optional[int]=None):\n",
    "    \"\"\"Split data into test and train sets.\"\"\"\n",
    "    if all([x.is_file() for x in (TRAIN_SET_DATA, TEST_SET_DATA)]):\n",
    "        train = pd.read_pickle(TRAIN_SET_DATA)\n",
    "        test = pd.read_pickle(TEST_SET_DATA)\n",
    "    else:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            d.drop(LABELS, axis=1),\n",
    "            d[LABELS],\n",
    "            test_size=0.18,\n",
    "            random_state=2,\n",
    "            stratify=stratify,\n",
    "        )\n",
    "    \n",
    "        train = x_train.join(y_train)\n",
    "        train.to_pickle(TRAIN_SET_DATA)\n",
    "        test = x_test.join(y_test)\n",
    "        test.to_pickle(TEST_SET_DATA)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "    \n",
    "weights, bins = pd.qcut(d['median_income'], q=5, labels=range(5), retbins=True)\n",
    "train_set, test_set = split_data(stratify=weights)\n",
    "x_train, x_test = [data_set.drop(LABELS, axis=1)\n",
    "                   for data_set in (train_set, test_set)]\n",
    "y_train, y_test = [data_set[LABELS] for data_set in (train_set, test_set)]\n",
    "N_TRAIN['total'] = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_diff(a: pd.Series, b: pd.Series) -> pd.Series:\n",
    "    \"\"\"Calculate the elementwise error difference between two series.\"\"\"\n",
    "    return (a - b) / b\n",
    "\n",
    "\n",
    "distribution = pd.concat(\n",
    "    [y_train.rename('train-median_value').describe(),\n",
    "     y_test.rename('test-median_value').describe(),\n",
    "     d['median_house_value'].rename('all_data-median_house_value').describe(),\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "distribution = distribution.join(\n",
    "    distribution[['train-median_value', 'test-median_value']]\n",
    "    .apply(lambda x: error_diff(x, distribution['all_data-median_house_value']))\n",
    "    .rename(columns={'train-median_value': 'train-error',\n",
    "                     'test-median_value': 'test-error'})\n",
    ")\n",
    "distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=d['median_income'],\n",
    "        marker={'color': 'blue'},\n",
    "        name='all data',\n",
    "        opacity=0.7,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=x_train['median_income'],\n",
    "        marker={'color': 'darkgray'},\n",
    "        name='train set',\n",
    "        opacity=0.7,\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=x_test['median_income'],\n",
    "        marker={'color': 'lightgray'},\n",
    "        name='test set',\n",
    "        opacity=0.7,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout({\n",
    "    'barmode': 'overlay',\n",
    "    'paper_bgcolor': 'rgba(0, 0, 0, 0)',\n",
    "    'plot_bgcolor': 'rgba(0, 0, 0, 0)',\n",
    "    'title': {\n",
    "        'font': TITLE_FONT,\n",
    "        'text': 'Median Income Distributions',\n",
    "        'x': 0.05,\n",
    "        'y': 0.90,\n",
    "    },\n",
    "    'xaxis': {\n",
    "        'side': 'bottom',\n",
    "        'tickangle': 0,\n",
    "        'tickfont': TICK_FONT,\n",
    "        'title': 'Median Income ($10k)',\n",
    "        'titlefont': AXIS_FONT,\n",
    "    },\n",
    "    'yaxis': {\n",
    "        'tickangle': 0,\n",
    "        'tickfont': TICK_FONT,\n",
    "        'title': 'Count',\n",
    "        'titlefont': AXIS_FONT,\n",
    "    },\n",
    "})\n",
    "iplot(fig, 'Median Income Distributions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Map Housing Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        hoverinfo='lat+lon+text' ,\n",
    "        hovertemplate=(\"longitude: %{lon}<br>\"\n",
    "                       + \"latitude: %{lat}<br>\"\n",
    "                       + \"median house value: %{text}\"\n",
    "                      ),\n",
    "        lon=x_train['longitude'],\n",
    "        lat=x_train['latitude'],\n",
    "        marker = {\n",
    "            'color': y_train,\n",
    "            'colorbar': {\n",
    "                'title': {\n",
    "                    'font': AXIS_FONT,\n",
    "                    'text': 'Median house value',\n",
    "                },\n",
    "            },\n",
    "            'colorscale': 'Jet',\n",
    "            'showscale': True,\n",
    "            'size': x_train['population'] / 100,\n",
    "            'sizemin': 7,\n",
    "            'opacity': 0.4,\n",
    "        },\n",
    "        mode='markers',\n",
    "        name='',\n",
    "        text=y_train,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout({\n",
    "    'width': 1000,\n",
    "    'height': 1000,\n",
    "    'margin': {'l':0, 'b': 0},\n",
    "    'mapbox': {\n",
    "        'center': {'lat': 37, 'lon': -119.5},\n",
    "        'style': 'stamen-terrain',\n",
    "        'zoom': 5.5,\n",
    "    },\n",
    "    'title': {\n",
    "        'font': TITLE_FONT,\n",
    "        'text': 'California Housing Prices',\n",
    "        'x': 0,\n",
    "        'y': 0.95,\n",
    "    },\n",
    "    'annotations': [{\n",
    "        'text': 'Marker size proportional to population density',\n",
    "        'font': AXIS_FONT,\n",
    "        'showarrow': False,\n",
    "        'x': 1,\n",
    "        'y': 1.03,\n",
    "        'xanchor': 'right',\n",
    "    }],\n",
    "})\n",
    "iplot(fig, 'Median House Value Map')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Scatter Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.corr()['median_house_value'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(\n",
    "    train_set,\n",
    "    dimensions=[\n",
    "        'longitude',\n",
    "        'latitude',\n",
    "        'total_rooms',\n",
    "        'total_bedrooms',\n",
    "        'households',\n",
    "        'median_income',\n",
    "        'median_house_value',\n",
    "    ],\n",
    "    color=y_train,\n",
    "    color_continuous_scale='Jet',\n",
    "    labels={x:x.replace('_', ' ') for x in d.columns},\n",
    "    opacity=0.3,\n",
    ")\n",
    "\n",
    "fig.update_traces({\n",
    "    'diagonal_visible': False,\n",
    "    'showupperhalf': False,\n",
    "})\n",
    "fig.update_layout({\n",
    "    'width': 1000,\n",
    "    'height': 1000,\n",
    "    'title': {\n",
    "        'font': TITLE_FONT,\n",
    "        'text': 'California Housing Prices Scatter Matrix',\n",
    "        'x': 0,\n",
    "        'y': 0.99,\n",
    "    },\n",
    "})\n",
    "iplot(fig, 'Scatter Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Effect of Median Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=train_set['median_income'],\n",
    "        y=y_train,\n",
    "        mode='markers',\n",
    "        opacity=0.3,\n",
    "    )\n",
    ")\n",
    "\n",
    "n_duplicate = 75\n",
    "count = y_train.value_counts()\n",
    "count = count[count >= n_duplicate]\n",
    "annotations = []\n",
    "shapes = []\n",
    "for val, cnt in count.iteritems():\n",
    "    annotations.append(\n",
    "        {\n",
    "            'bgcolor': 'white',\n",
    "            'text': cnt,\n",
    "            'showarrow': False,\n",
    "            'xref': 'paper',\n",
    "            'yref': 'y',\n",
    "            'x': 1,\n",
    "            'y': val,\n",
    "            'xanchor': 'right',\n",
    "        }\n",
    "    )\n",
    "    shapes.append(\n",
    "        {\n",
    "            'type': 'line',\n",
    "            'xref': 'paper',\n",
    "            'yref': 'y',\n",
    "            'x0': 0,\n",
    "            'y0': val,\n",
    "            'x1': 1,\n",
    "            'y1': val,\n",
    "            'line': {\n",
    "                'color': 'red',\n",
    "                'dash': 'dashdot',\n",
    "                'width': 1,\n",
    "            },\n",
    "            'opacity': 0.7,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "\n",
    "    \n",
    "annotations.append(\n",
    "    {\n",
    "        'text': f'Count of instances where value is duplicated at least {n_duplicate} times',\n",
    "        'font': AXIS_FONT,\n",
    "        'showarrow': False,\n",
    "        'xref': 'paper',\n",
    "        'yref': 'paper',\n",
    "        'x': 1,\n",
    "        'y': 1.015,\n",
    "        'xanchor': 'right',\n",
    "    }\n",
    ")\n",
    "\n",
    "shapes.append(\n",
    "    {\n",
    "        'type': 'line',\n",
    "        'xref': 'paper',\n",
    "        'yref': 'paper',\n",
    "        'x0': 0.37,\n",
    "        'y0': 1,\n",
    "        'x1': 0.4,\n",
    "        'y1': 1,\n",
    "        'line': {\n",
    "            'color': 'red',\n",
    "            'dash': 'dashdot',\n",
    "            'width': 1,\n",
    "        },\n",
    "        'opacity': 0.7,\n",
    "    }\n",
    ")\n",
    "fig.update_layout({\n",
    "    'width': 1000,\n",
    "    'height': 1000,\n",
    "    'annotations': annotations,\n",
    "    'paper_bgcolor': 'rgba(0, 0, 0, 0)',\n",
    "    'plot_bgcolor': 'rgba(0, 0, 0, 0)',\n",
    "    'shapes': shapes,\n",
    "    'title': {\n",
    "        'font': TITLE_FONT,\n",
    "        'text': 'House Median Value vs Median Income',\n",
    "        'x': 0,\n",
    "        'y': 0.95,\n",
    "    },\n",
    "    'xaxis': {\n",
    "        'side': 'bottom',\n",
    "        'tickangle': 0,\n",
    "        'tickfont': TICK_FONT,\n",
    "        'title': 'Median Income ($10k)',\n",
    "        'titlefont': AXIS_FONT,\n",
    "    },\n",
    "    'yaxis': {\n",
    "        'tickangle': 0,\n",
    "        'tickfont': TICK_FONT,\n",
    "        'title': 'Median Value',\n",
    "        'titlefont': AXIS_FONT,\n",
    "    },\n",
    "})\n",
    "iplot(fig, 'Value vs. Income')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Attribute Combinations\n",
    "\n",
    "- Custom transformer classes must have the following metheds:\n",
    "    - fit()\n",
    "    - transform()\n",
    "    - fit_transform()\n",
    "- Inheriting TransformerMixin will define fit_transform() method.\n",
    "- Inheriting BaseEstimator will define get_params() and set_params() methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedFeatures(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Class to create combined features.\n",
    "    \n",
    "    Input matrix will be result of an Imputer (an array not a data frame).\n",
    "    \"\"\"   \n",
    "    def __init__(self, add_bedrooms_per_room: bool=True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "        \n",
    "        num_cols = x_train.select_dtypes(include=[np.number]).columns\n",
    "        ids = {k: n for n, k in enumerate(num_cols)}\n",
    "        self.rooms_col = ids['total_rooms']\n",
    "        self.bedrooms_col = ids['total_bedrooms']\n",
    "        self.population_col = ids['population']\n",
    "        self.households_col = ids['households']\n",
    "    \n",
    "    def fit(self, x: np.array):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x: np.array):\n",
    "        avg_rooms = x[:, self.rooms_col] / x[:, self.households_col]\n",
    "        population_per_house = x[:, self.population_col] / x[:, self.households_col]\n",
    "        out = np.c_[x, avg_rooms, population_per_house]\n",
    "        \n",
    "        if self.add_bedrooms_per_room:\n",
    "            avg_bedrooms = x[:, self.bedrooms_col] / x[:, self.rooms_col]\n",
    "            out = np.c_[out, avg_bedrooms]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Prepare Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove instances with the capped median value of $500k\n",
    "\n",
    "This data will not help the algorithm learn an acurate home value.\n",
    "The districts with high home values should be evaluated to determine if \n",
    "additional data in this regiem is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_max_value(features: pd.DataFrame,\n",
    "                 home_values: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Remove the examples with maximum home value.\n",
    "    \n",
    "    :param features: input features\n",
    "    :param home_values: home median values (labels)\n",
    "\n",
    "    The median_house_value field was capped at $500,0001.  This data is being \n",
    "    removed, since it will will not improve the prediction algorithm.\n",
    "    \"\"\"\n",
    "    y = home_values[home_values < 500001]\n",
    "    x = features.loc[y.index]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "x_train, y_train = rm_max_value(x_train, y_train)\n",
    "x_test, y_test = rm_max_value(x_test, y_test)\n",
    "\n",
    "N_TRAIN['remove_capped_value'] = len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline = Pipeline(\n",
    "    [\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('combined_features', CombinedFeatures()),\n",
    "        ('min_max_scaler', MinMaxScaler()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    'ocean_proximity',\n",
    "]\n",
    "numerical_features = x_train.columns.drop(categorical_features)\n",
    "pipeline = ColumnTransformer(\n",
    "    [\n",
    "        ('numeric', numerical_pipeline, numerical_features),\n",
    "        ('categorical', OneHotEncoder(), categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepared Data\n",
    "\n",
    "- 9 original features\n",
    "- +3 combined features\n",
    "- +5 one hot encodings from *ocean_proximity'\n",
    "- -1 for *ocean_proximity'\n",
    "\n",
    "Input array should be (n X 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_prepared = pipeline.fit_transform(x_train)\n",
    "x_train_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, \n",
    "                   features=x_train_prepared,\n",
    "                   labels=y_train,\n",
    "                   kfold=False):\n",
    "    \"\"\"\n",
    "    Train and evaluate model with provided data sets.\n",
    "    \n",
    "    :param model: model to be evaluated\n",
    "    :param features: input features\n",
    "    :labels: output truth values\n",
    "    :kfold: if True the cross-validation will be used\n",
    "    :returns: model and root mean squared error (L2 norm)\n",
    "    \"\"\"\n",
    "    m = model\n",
    "    m.fit(features, labels)\n",
    "    y_hat = m.predict(features)\n",
    "    if kfold:\n",
    "        scores = cross_val_score(m, features, labels,\n",
    "                                 scoring=\"neg_mean_squared_error\", cv=10)\n",
    "        rmse_arr = np.sqrt(-scores)\n",
    "        rmse = (rmse_arr, rmse_arr.mean(), rmse_arr.std())\n",
    "    else:\n",
    "        rmse = np.sqrt(mean_squared_error(labels, y_hat))\n",
    "    return m, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model, lr_rmse = evaluate_model(LinearRegression())\n",
    "lr_kfold_model, lr_kfold_rmse = evaluate_model(LinearRegression(), kfold=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model, dt_rmse = evaluate_model(DecisionTreeRegressor())\n",
    "dt_kfold_model, dt_kfold_rmse = evaluate_model(DecisionTreeRegressor(), \n",
    "                                               kfold=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model, rf_rmse = evaluate_model(RandomForestRegressor())\n",
    "rf_kfold_model, rf_kfold_rmse = evaluate_model(RandomForestRegressor(),\n",
    "                                               kfold=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model, svm_rmse = evaluate_model(svm.SVR())\n",
    "svm_kfold_model, svm_kfold_rmse = evaluate_model(svm.SVR(), kfold=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glr_model, glr_rmse = evaluate_model(TweedieRegressor(power=2, alpha=0.5, \n",
    "                                                      link='log'))\n",
    "glr_kfold_model, glr_kfold_rmse = evaluate_model(TweedieRegressor(power=2, alpha=0.5,\n",
    "                                                                 link='log'),\n",
    "                                                 kfold=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LR\": lr_kfold_rmse[1:],\n",
    "    \"DT\": dt_kfold_rmse[1:],\n",
    "    \"RF\": rf_kfold_rmse[1:],\n",
    "    \"SVM\": svm_kfold_rmse[1:],\n",
    "    \"GLR\": glr_kfold_rmse[1:],    \n",
    "}\n",
    "\n",
    "(pd.DataFrame\n",
    " .from_dict(models, orient='index', columns=['Mean', \"STD\"])\n",
    " .sort_values('Mean')\n",
    " .style.highlight_min(color='lightgreen')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Fine Tune Model\n",
    "\n",
    "The Random Forest model appears to be the most promising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = [\n",
    "    {\n",
    "        'max_features': [4, 8, 16],\n",
    "        'n_estimators': [10, 50, 100],\n",
    "    },\n",
    "    {\n",
    "        'bootstrap': [False],\n",
    "        'max_features': [4, 8, 16],\n",
    "        'n_estimators': [10, 50, 100]\n",
    "    },\n",
    "]\n",
    "model = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(\n",
    "    model,\n",
    "    parameter_grid,\n",
    "    cv=4,\n",
    "    return_train_score=True,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "grid_search.fit(x_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hyperparameter_search(results):\n",
    "    summary = pd.DataFrame.from_dict(\n",
    "        {k: v for k, v in results.items()\n",
    "         if k in ('params', 'mean_test_score', 'std_test_score')}\n",
    "    )\n",
    "    summary['mean_test_score'] = np.sqrt(-summary['mean_test_score'])\n",
    "    summary['std_test_score'] = np.sqrt(summary['std_test_score'])\n",
    "    summary['max_score'] = summary['mean_test_score'] + summary['std_test_score']\n",
    "    return (summary\n",
    "            .sort_values('max_score')\n",
    "            .style.highlight_min(color='lightgreen')\n",
    "           )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_hyperparameter_search(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Best Parameters\n",
    "\n",
    "- `bootstrap = False`\n",
    "- `max_features = 8`\n",
    "- `n_estimators = 100`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = {\n",
    "    'bootstrap': [False],\n",
    "    'max_features': range(4, 17),\n",
    "    'n_estimators': range(10, 101),\n",
    "}\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "random_search = RandomizedSearchCV(\n",
    "    model,\n",
    "    distributions,\n",
    "    return_train_score=True,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_iter=16,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "random_search.fit(x_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_hyperparameter_search(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Display Feature Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importances = random_search.best_estimator_.feature_importances_\n",
    "extra_features = ['avg_rooms', 'population_per_house', 'avg_bedrooms']\n",
    "category_encoder = pipeline.named_transformers_['categorical']\n",
    "category_one_hot_features = list(category_encoder.categories_[0])\n",
    "attributes = (numerical_features.to_list()\n",
    "              + extra_features\n",
    "              + category_one_hot_features)\n",
    "\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluate Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = random_search.best_estimator_\n",
    "x_test_prepared = pipeline.transform(x_test)\n",
    "test_predictions = final_model.predict(x_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, test_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "print(f'MSE = {final_mse}\\nRMSE = {final_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE Interpretation\n",
    "- Train Set = 44127\n",
    "- Test Set = 44954\n",
    "\n",
    "The model generalized to new data very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model 95% Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 0.95\n",
    "squared_errors = (test_predictions - y_test)**2\n",
    "np.sqrt(stats.t.interval(confidence,\n",
    "                         len(squared_errors) - 1,\n",
    "                         loc=squared_errors.mean(),\n",
    "                         scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With 95% Confidence the model will be at worst $47,014 from the actual value.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
